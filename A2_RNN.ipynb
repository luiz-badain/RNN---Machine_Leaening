{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwTtATCd/+mlU/Oe/vR3W1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugyd5Fvxyjh0",
        "outputId": "53039ff7-e943-43df-e2b0-e4677bc04b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 3.5259 - accuracy: 0.0227\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.5182 - accuracy: 0.0909\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.5123 - accuracy: 0.1364\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.5067 - accuracy: 0.1364\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.5010 - accuracy: 0.2045\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.4952 - accuracy: 0.1818\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.4886 - accuracy: 0.1818\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4823 - accuracy: 0.1818\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4744 - accuracy: 0.1818\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.4656 - accuracy: 0.1818\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4562 - accuracy: 0.1818\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.4436 - accuracy: 0.1818\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4295 - accuracy: 0.1818\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.4145 - accuracy: 0.1818\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.3928 - accuracy: 0.1818\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.3703 - accuracy: 0.1818\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.3402 - accuracy: 0.1818\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.3060 - accuracy: 0.1818\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2627 - accuracy: 0.1818\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2129 - accuracy: 0.1818\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1709 - accuracy: 0.1818\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1221 - accuracy: 0.1818\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1067 - accuracy: 0.1818\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1068 - accuracy: 0.1818\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.0902 - accuracy: 0.1818\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.0569 - accuracy: 0.1818\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.0209 - accuracy: 0.1818\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.0106 - accuracy: 0.1818\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9970 - accuracy: 0.1818\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.9792 - accuracy: 0.1818\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9599 - accuracy: 0.2045\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9357 - accuracy: 0.2045\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.9090 - accuracy: 0.2045\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.8905 - accuracy: 0.2045\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.8791 - accuracy: 0.2045\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.8647 - accuracy: 0.2045\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.8433 - accuracy: 0.2045\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.8151 - accuracy: 0.2273\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.7950 - accuracy: 0.2273\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7757 - accuracy: 0.2273\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7581 - accuracy: 0.2273\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7346 - accuracy: 0.2273\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7093 - accuracy: 0.2273\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.6865 - accuracy: 0.2273\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.6622 - accuracy: 0.2273\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6385 - accuracy: 0.2273\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6116 - accuracy: 0.2273\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.5824 - accuracy: 0.2273\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.5593 - accuracy: 0.2273\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.5247 - accuracy: 0.2273\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4972 - accuracy: 0.2273\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4676 - accuracy: 0.2273\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4387 - accuracy: 0.2273\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4057 - accuracy: 0.2500\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3684 - accuracy: 0.2727\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.3335 - accuracy: 0.2955\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2962 - accuracy: 0.3182\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.2559 - accuracy: 0.3409\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2218 - accuracy: 0.3409\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.1789 - accuracy: 0.3409\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.1348 - accuracy: 0.4091\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0950 - accuracy: 0.4091\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0587 - accuracy: 0.4318\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0178 - accuracy: 0.4318\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9707 - accuracy: 0.4545\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9214 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8706 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8389 - accuracy: 0.4545\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7921 - accuracy: 0.4773\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.7424 - accuracy: 0.5455\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6874 - accuracy: 0.5682\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6437 - accuracy: 0.5682\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6063 - accuracy: 0.5682\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5689 - accuracy: 0.5682\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5290 - accuracy: 0.5682\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4818 - accuracy: 0.5909\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4481 - accuracy: 0.5909\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4075 - accuracy: 0.6591\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3748 - accuracy: 0.6591\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3330 - accuracy: 0.6591\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.3004 - accuracy: 0.6136\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2868 - accuracy: 0.5909\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2521 - accuracy: 0.5909\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2325 - accuracy: 0.7045\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2316 - accuracy: 0.6364\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1968 - accuracy: 0.6136\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1483 - accuracy: 0.7045\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1464 - accuracy: 0.6136\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1308 - accuracy: 0.6364\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1110 - accuracy: 0.6591\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0906 - accuracy: 0.6818\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0757 - accuracy: 0.7045\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0514 - accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0192 - accuracy: 0.7273\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0008 - accuracy: 0.7045\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0020 - accuracy: 0.6591\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9868 - accuracy: 0.6591\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9638 - accuracy: 0.7273\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9664 - accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9485 - accuracy: 0.7727\n",
            "Digite uma frase inicial: RNN\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "Sugestões: é, amo, quero\n",
            "Digite a próxima palavra, escolha uma das sugestões, ou pressione '0' para finalizar: é\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Sugestões: chato, muito, um\n",
            "Digite a próxima palavra, escolha uma das sugestões, ou pressione '0' para finalizar: muito\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Sugestões: em, chato, modelo\n",
            "Digite a próxima palavra, escolha uma das sugestões, ou pressione '0' para finalizar: chato\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Sugestões: 10, deep, incrível\n",
            "Digite a próxima palavra, escolha uma das sugestões, ou pressione '0' para finalizar: 0\n",
            "Frase completa: \"RNN é muito chato\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Função para ler dados de um arquivo txt\n",
        "def ler_dados_txt(caminho_arquivo):\n",
        "    with open(caminho_arquivo, 'r', encoding='utf-8') as file:\n",
        "        linhas = file.readlines()\n",
        "    corpus = [linha.strip() for linha in linhas if linha.strip()]\n",
        "    return corpus\n",
        "\n",
        "# Caminho do arquivo txt\n",
        "caminho_arquivo = 'dados.txt'\n",
        "\n",
        "# Ler o corpus do arquivo txt\n",
        "corpus = ler_dados_txt(caminho_arquivo)\n",
        "\n",
        "# Preparação dos dados\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Criar pares de entrada e saída\n",
        "input_sequences = []\n",
        "target_words = []\n",
        "\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        n_gram_sequence = sequence[:i+1]\n",
        "        input_sequences.append(n_gram_sequence[:-1])\n",
        "        target_words.append(n_gram_sequence[-1])\n",
        "\n",
        "# Padronizar o comprimento das sequências de entrada\n",
        "max_seq_length = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_length, padding='pre')\n",
        "\n",
        "input_sequences = np.array(input_sequences)\n",
        "target_words = np.array(target_words)\n",
        "\n",
        "# Criar o modelo RNN\n",
        "modelo = Sequential()\n",
        "modelo.add(Embedding(vocab_size, 10, input_length=max_seq_length))\n",
        "modelo.add(SimpleRNN(50, activation='relu'))\n",
        "modelo.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo.fit(input_sequences, target_words, epochs=100)\n",
        "\n",
        "# Função para prever a próxima palavra\n",
        "def prever_proxima_palavra(modelo, tokenizer, texto, num_sugestoes=3):\n",
        "    sequence = tokenizer.texts_to_sequences([texto])[0]\n",
        "    sequence = pad_sequences([sequence], maxlen=max_seq_length, padding='pre')\n",
        "    predictions = modelo.predict(sequence)\n",
        "    sorted_indices = np.argsort(predictions[0])[-num_sugestoes:][::-1]\n",
        "    sugestoes = [word for word, index in tokenizer.word_index.items() if index in sorted_indices]\n",
        "    return sugestoes\n",
        "\n",
        "# Função para construir a frase interativamente\n",
        "def construir_frase_interativamente(modelo, tokenizer, texto_inicial, max_len=20):\n",
        "    texto_atual = texto_inicial\n",
        "    while len(texto_atual.split()) < max_len:\n",
        "        sugestoes = prever_proxima_palavra(modelo, tokenizer, texto_atual, num_sugestoes=3)\n",
        "        if len(sugestoes) == 0:\n",
        "            break\n",
        "        print(f'Sugestões: {\", \".join(sugestoes)}')\n",
        "        user_input = input(\"Digite a próxima palavra ou escolha uma das sugestões, e pressione '0' caso queira finalizar: \").strip()\n",
        "        if user_input == '0':\n",
        "            break\n",
        "        if user_input and user_input in sugestoes:\n",
        "            texto_atual += ' ' + user_input\n",
        "        elif user_input:\n",
        "            texto_atual += ' ' + user_input\n",
        "        else:\n",
        "            texto_atual += ' ' + sugestoes[0]\n",
        "    return texto_atual\n",
        "\n",
        "# Solicitar a frase inicial ao usuário\n",
        "texto_inicial = input(\"Digite uma frase inicial: \")\n",
        "frase_completa = construir_frase_interativamente(modelo, tokenizer, texto_inicial)\n",
        "\n",
        "print(f'Frase completa: \"{frase_completa}\"')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}